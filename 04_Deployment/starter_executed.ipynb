{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f77871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T11:53:22.788275Z",
     "iopub.status.busy": "2025-06-18T11:53:22.788083Z",
     "iopub.status.idle": "2025-06-18T11:53:26.749433Z",
     "shell.execute_reply": "2025-06-18T11:53:26.749183Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_loading",
   "metadata": {},
   "source": [
    "### Load the model and vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T11:53:26.750887Z",
     "iopub.status.busy": "2025-06-18T11:53:26.750748Z",
     "iopub.status.idle": "2025-06-18T11:53:45.402219Z",
     "shell.execute_reply": "2025-06-18T11:53:45.401655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully\n"
     ]
    }
   ],
   "source": [
    "# For this homework, we'll create a simple model first\n",
    "# In practice, you would load a pre-trained model\n",
    "\n",
    "# Load training data to create model\n",
    "df_jan = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "\n",
    "# Compute duration\n",
    "df_jan['duration'] = (df_jan['tpep_dropoff_datetime'] - df_jan['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Filter outliers\n",
    "df_jan = df_jan[(df_jan['duration'] >= 1) & (df_jan['duration'] <= 60)].copy()\n",
    "\n",
    "# Prepare features\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "df_jan[categorical] = df_jan[categorical].astype(str)\n",
    "\n",
    "train_dicts = df_jan[categorical].to_dict(orient='records')\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "y_train = df_jan['duration'].values\n",
    "\n",
    "# Train model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('Model trained successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {},
   "source": [
    "### Load March 2023 data for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_data",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T11:53:45.404032Z",
     "iopub.status.busy": "2025-06-18T11:53:45.403905Z",
     "iopub.status.idle": "2025-06-18T11:53:49.481090Z",
     "shell.execute_reply": "2025-06-18T11:53:49.480797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 3403766 records\n"
     ]
    }
   ],
   "source": [
    "# Load March 2023 data\n",
    "year = 2023\n",
    "month = 3\n",
    "\n",
    "df = pd.read_parquet(f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year:04d}-{month:02d}.parquet')\n",
    "\n",
    "print(f'Data loaded: {len(df)} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "preprocess",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T11:53:49.482441Z",
     "iopub.status.busy": "2025-06-18T11:53:49.482332Z",
     "iopub.status.idle": "2025-06-18T11:53:50.347718Z",
     "shell.execute_reply": "2025-06-18T11:53:50.347456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after filtering: 3316216 records\n"
     ]
    }
   ],
   "source": [
    "# Compute duration\n",
    "df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Filter outliers\n",
    "df = df[(df['duration'] >= 1) & (df['duration'] <= 60)].copy()\n",
    "\n",
    "# Prepare categorical features\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "print(f'Data after filtering: {len(df)} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prediction",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "predict",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T11:53:50.348878Z",
     "iopub.status.busy": "2025-06-18T11:53:50.348798Z",
     "iopub.status.idle": "2025-06-18T11:53:54.889711Z",
     "shell.execute_reply": "2025-06-18T11:53:54.889397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions made for 3316216 records\n"
     ]
    }
   ],
   "source": [
    "# Transform features\n",
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X = dv.transform(dicts)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr.predict(X)\n",
    "\n",
    "print(f'Predictions made for {len(y_pred)} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1_answer",
   "metadata": {},
   "source": [
    "### Q1: Standard deviation of predicted duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "q1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T11:53:54.890907Z",
     "iopub.status.busy": "2025-06-18T11:53:54.890826Z",
     "iopub.status.idle": "2025-06-18T11:53:54.896310Z",
     "shell.execute_reply": "2025-06-18T11:53:54.896038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of predicted duration: 6.25\n"
     ]
    }
   ],
   "source": [
    "# Calculate standard deviation of predictions\n",
    "std_pred = np.std(y_pred)\n",
    "print(f'Standard deviation of predicted duration: {std_pred:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2_output",
   "metadata": {},
   "source": [
    "### Q2: Prepare output and save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "q2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T11:53:54.897476Z",
     "iopub.status.busy": "2025-06-18T11:53:54.897397Z",
     "iopub.status.idle": "2025-06-18T11:53:55.463007Z",
     "shell.execute_reply": "2025-06-18T11:53:55.462737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to predictions_2023_03.parquet\n"
     ]
    }
   ],
   "source": [
    "# Create ride_id column\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "# Create results dataframe\n",
    "df_result = pd.DataFrame({\n",
    "    'ride_id': df['ride_id'],\n",
    "    'predicted_duration': y_pred\n",
    "})\n",
    "\n",
    "# Save as parquet\n",
    "output_file = f'predictions_{year:04d}_{month:02d}.parquet'\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f'Results saved to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "check_file_size",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T11:53:55.464142Z",
     "iopub.status.busy": "2025-06-18T11:53:55.464054Z",
     "iopub.status.idle": "2025-06-18T11:53:55.465965Z",
     "shell.execute_reply": "2025-06-18T11:53:55.465757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 65M\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check file size\n",
    "file_size = os.path.getsize(output_file)\n",
    "file_size_mb = file_size / (1024 * 1024)\n",
    "print(f'File size: {file_size_mb:.0f}M')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
